{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balsrini/Hackathon2019/blob/master/Second.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dZ3-uXvmqip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ed5649b-6769-47d1-a00a-81f0a049f898"
      },
      "source": [
        "from os import listdir\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer, one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Embedding, TimeDistributed, RepeatVector, LSTM, concatenate , Input, Reshape, Dense, Flatten\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNQv9vaawiN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb7d5bbc-51d0-4a37-9b73-99382d664e38"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#all_filenames = listdir('gdrive/hackathon2019/images/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Xc3cQFx8EN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "369a4690-4b09-4b7a-ea63-472a33bd7c3f"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['86.jpg', '87.jpg', '88.jpg', '89.jpg', '90.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8kDTp-3msGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "a7ebba67-a928-4767-ec96-e6993419dd47"
      },
      "source": [
        "\n",
        "images = []\n",
        "all_filenames = listdir('/content/gdrive/My Drive/hackathon2019/images')\n",
        "print(all_filenames)\n",
        "all_filenames.sort()\n",
        "for filename in all_filenames:      \n",
        "    images.append(img_to_array(load_img('/content/gdrive/My Drive/hackathon2019/images/' + filename, target_size=(299, 299))))\n",
        "images = np.array(images, dtype=float)\n",
        "images = preprocess_input(images)\n",
        "\n",
        "# Run the images through inception-resnet and extract the features without the classification layer\n",
        "IR2 = InceptionResNetV2(weights='imagenet', include_top=False)\n",
        "features = IR2.predict(images)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['86.jpg', '87.jpg', '88.jpg', '89.jpg', '90.jpg']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0724 12:11:43.215019 140486089746304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0724 12:11:43.257253 140486089746304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0724 12:11:43.270066 140486089746304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0724 12:11:43.333410 140486089746304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0724 12:11:43.335178 140486089746304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0724 12:11:43.655911 140486089746304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0724 12:11:44.039791 140486089746304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0724 12:11:44.745827 140486089746304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "friWZeFEmyqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "069da9d1-ed93-4222-ff99-3cc59fa199e1"
      },
      "source": [
        "# We will cap each input sequence to 100 tokens\n",
        "max_caption_len = 100\n",
        "# Initialize the function that will create our vocabulary \n",
        "tokenizer = Tokenizer(filters='', split=\" \", lower=False)\n",
        "\n",
        "# Read a document and return a string\n",
        "def load_doc(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# Load all the HTML files\n",
        "X = []\n",
        "all_filenames = listdir('/content/gdrive/My Drive/hackathon2019/html/')\n",
        "all_filenames.sort()\n",
        "print(all_filenames)\n",
        "for filename in all_filenames:\n",
        "    X.append(load_doc('/content/gdrive/My Drive/hackathon2019/html/'+filename))\n",
        "\n",
        "# Create the vocabulary from the html files\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "# Add +1 to leave space for empty words\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "# Translate each word in text file to the matching vocabulary index\n",
        "sequences = tokenizer.texts_to_sequences(X)\n",
        "# The longest HTML file\n",
        "max_length = max(len(s) for s in sequences)\n",
        "\n",
        "# Intialize our final input to the model\n",
        "X, y, image_data = list(), list(), list()\n",
        "for img_no, seq in enumerate(sequences):\n",
        "    for i in range(1, len(seq)):\n",
        "        # Add the entire sequence to the input and only keep the next word for the output\n",
        "        in_seq, out_seq = seq[:i], seq[i]\n",
        "        # If the sentence is shorter than max_length, fill it up with empty words\n",
        "        in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "        # Map the output to one-hot encoding\n",
        "        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "        # Add and image corresponding to the HTML file\n",
        "        image_data.append(features[img_no])\n",
        "        # Cut the input sentence to 100 tokens, and add it to the input data\n",
        "        X.append(in_seq[-100:])\n",
        "        y.append(out_seq)\n",
        "\n",
        "X, y, image_data = np.array(X), np.array(y), np.array(image_data)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['86.html', '87.html', '88.html', '89.html', '90.html']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTHQZCkxGU24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "08d20969-fd74-426f-aae7-994650a09a5e"
      },
      "source": [
        "images = []\n",
        "all_filenames = listdir('/content/gdrive/My Drive/hackathon2019/images/')\n",
        "all_filenames.sort()\n",
        "for filename in all_filenames:\n",
        "    print(filename)\n",
        "    images.append(img_to_array(load_img('/content/gdrive/My Drive/hackathon2019/images/'+filename, target_size=(299, 299))))\n",
        "images = np.array(images, dtype=float)\n",
        "images = preprocess_input(images)\n",
        "\n",
        "IR2 = InceptionResNetV2(weights=None, include_top=False, pooling='avg')\n",
        "#IR2.load_weights('/data/models/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "features = IR2.predict(images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "max_caption_len = 100\n",
        "tokenizer = Tokenizer(filters='', split=\" \", lower=False)\n",
        "\n",
        "def load_doc(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "X = []\n",
        "all_filenames = listdir('/content/gdrive/My Drive/hackathon2019/html/')\n",
        "all_filenames.sort()\n",
        "for filename in all_filenames:\n",
        "    X.append(load_doc('/content/gdrive/My Drive/hackathon2019/html/'+filename))\n",
        "\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(X)\n",
        "max_length = max(len(s) for s in sequences)\n",
        " \n",
        "X, y, image_data = list(), list(), list()\n",
        "for img_no, seq in enumerate(sequences):\n",
        "    for i in range(1, len(seq)):\n",
        "        in_seq, out_seq = seq[:i], seq[i]\n",
        "        in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "        image_data.append(features[img_no])\n",
        "        X.append(in_seq[-100:])\n",
        "        y.append(out_seq)\n",
        "\n",
        "X, y, image_data = np.array(X), np.array(y), np.array(image_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0724 13:16:34.510891 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0724 13:16:34.545394 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0724 13:16:34.556464 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "86.jpg\n",
            "87.jpg\n",
            "88.jpg\n",
            "89.jpg\n",
            "90.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0724 13:16:34.619576 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0724 13:16:34.621147 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0724 13:16:34.925717 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0724 13:16:35.369212 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0724 13:16:36.132690 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BswvBi_Mm0QF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5be2a1d3-253e-43da-81c7-fd35e90bb036"
      },
      "source": [
        "image_features = Input(shape=(1536,))\n",
        "image_flat = Dense(128, activation='relu')(image_features)\n",
        "ir2_out = RepeatVector(max_caption_len)(image_flat)\n",
        "\n",
        "language_input = Input(shape=(max_caption_len,))\n",
        "language_model = Embedding(vocab_size, 200, input_length=max_caption_len)(language_input)\n",
        "language_model = LSTM(256, return_sequences=True)(language_model)\n",
        "language_model = LSTM(256, return_sequences=True)(language_model)\n",
        "language_model = TimeDistributed(Dense(128, activation='relu'))(language_model)\n",
        "\n",
        "decoder = concatenate([ir2_out, language_model])\n",
        "decoder = LSTM(512, return_sequences=True)(decoder)\n",
        "decoder = LSTM(512, return_sequences=False)(decoder)\n",
        "decoder_output = Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "model = Model(inputs=[image_features, language_input], outputs=decoder_output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create the encoder\n",
        "#image_features = Input(shape=(8, 8, 1536,))\n",
        "#image_flat = Flatten()(image_features)\n",
        "#image_flat = Dense(128, activation='relu')(image_flat)\n",
        "#ir2_out = RepeatVector(max_caption_len)(image_flat)\n",
        "\n",
        "#language_input = Input(shape=(max_caption_len,))\n",
        "#language_model = Embedding(vocab_size, 200, input_length=max_caption_len)(language_input)\n",
        "#language_model = LSTM(256, return_sequences=True)(language_model)\n",
        "#language_model = LSTM(256, return_sequences=True)(language_model)\n",
        "#language_model = TimeDistributed(Dense(128, activation='relu'))(language_model)\n",
        "\n",
        "# Create the decoder\n",
        "#decoder = concatenate([ir2_out, language_model])\n",
        "#decoder = LSTM(512, return_sequences=False)(decoder)\n",
        "#decoder_output = Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "# Compile the model\n",
        "#model = Model(inputs=[image_features, language_input], outputs=decoder_output)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0724 13:17:21.108511 139652538976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNmcQ3Vfm2bN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "1ce4c28d-4cb5-4211-a42c-fe7316d22224"
      },
      "source": [
        "# Train the neural network\n",
        "\n",
        "print(image_data.shape)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(features.shape)\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#Train model\n",
        "filepath=\"/content/gdrive/My Drive/hackathon2019/org-weights-epoch-1000---loss-0.0000.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=True, period=50)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model.fit([image_data, X], y, batch_size=1000, callbacks=callbacks_list, shuffle=False, epochs=1000)\n",
        "\n",
        "#model.fit([image_data, X], y, batch_size=64, shuffle=False, epochs=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0724 13:17:41.331499 139652538976128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(2306, 1536)\n",
            "(2306, 100)\n",
            "(2306, 436)\n",
            "(5, 1536)\n",
            "Epoch 1/1000\n",
            "2306/2306 [==============================] - 154s 67ms/step - loss: 6.1726\n",
            "Epoch 2/1000\n",
            "2306/2306 [==============================] - 155s 67ms/step - loss: 6.0474\n",
            "Epoch 3/1000\n",
            "2306/2306 [==============================] - 154s 67ms/step - loss: 5.7893\n",
            "Epoch 4/1000\n",
            "2306/2306 [==============================] - 152s 66ms/step - loss: 5.7668\n",
            "Epoch 5/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a6dc9869c554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#model.fit([image_data, X], y, batch_size=64, shuffle=False, epochs=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDPmZYNMm6yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6pja6Ghm8xN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# generate a description for an image\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    # seed the generation process\n",
        "    in_text = 'START'\n",
        "    # iterate over the whole length of the sequence\n",
        "    for i in range(900):\n",
        "        # integer encode input sequence\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0][-100:]\n",
        "        # pad input\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        # predict next word\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "       # print(yhat)\n",
        "        # convert probability to integer\n",
        "        yhat = np.argmax(yhat)\n",
        "        # map integer to word\n",
        "        word = word_for_id(yhat, tokenizer)\n",
        "        #print(word)\n",
        "        # stop if we cannot map the word\n",
        "        if word is None:\n",
        "            break\n",
        "        # append as input for generating the next word\n",
        "        in_text += ' ' + word\n",
        "        # Print the prediction\n",
        "        print(' ' + word, end='')\n",
        "        # stop if we predict the end of the sequence\n",
        "        if word == 'END':\n",
        "            break\n",
        "    return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wlbtSVXnAEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6e67fd3-b3b4-4086-a1ad-a033cc642bf2"
      },
      "source": [
        "\n",
        "\n",
        "# Load and image, preprocess it for IR2, extract features and generate the HTML\n",
        "test_image = img_to_array(load_img('/content/gdrive/My Drive/hackathon2019/images/87.jpg', target_size=(299, 299)))\n",
        "print(test_image.shape)\n",
        "model.load_weights('/content/gdrive/My Drive/hackathon2019/org-weights-epoch-1000---loss-0.0000.hdf5')\n",
        "test_image = np.array(test_image, dtype=float)\n",
        "test_image = preprocess_input(test_image)\n",
        "test_features = IR2.predict(np.array([test_image]))\n",
        "generate_desc(model, tokenizer, np.array(test_features), 100)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(299, 299, 3)\n",
            " <!DOCTYPE html>\n",
            "<html lang=\"en\" dir=\"ltr\">\n",
            "<head>\n",
            "<title>Basic 86</title>\n",
            "<meta charset=\"iso-8859-1\">\n",
            "<link rel=\"stylesheet\" href=\"styles/layout.css\" type=\"text/css\">\n",
            "<!--[if lt IE 9]><script src=\"scripts/html5shiv.js\"></script><![endif]-->\n",
            "</head>\n",
            "<body>\n",
            "<div class=\"wrapper row1\">\n",
            " <header id=\"header\" class=\"clear\">\n",
            " <div id=\"hgroup\">\n",
            " <h1><a href=\"#\">Basic 86</a></h1>\n",
            " <h2>Free HTML5 Website Template</h2>\n",
            " </div>\n",
            " <nav>\n",
            " <ul>\n",
            " <li><a href=\"#\">Text Link</a></li>\n",
            " <li><a href=\"#\">Text Link</a></li>\n",
            " <li><a href=\"#\">Text Link</a></li>\n",
            " <li><a href=\"#\">Text Link</a></li>\n",
            " <li class=\"last\"><a href=\"#\">Text Link</a></li>\n",
            " </ul>\n",
            " </nav>\n",
            " </header>\n",
            "</div>\n",
            "<!-- content -->\n",
            "<div class=\"wrapper row2\">\n",
            " <div id=\"container\" class=\"clear\">\n",
            " <!-- Slider -->\n",
            " <section id=\"slider\" class=\"clear\">\n",
            " <figure><img src=\"images/demo/630x300.gif\" alt=\"\">\n",
            " <figcaption>\n",
            " <h2>Eu justo augue estas</h2>\n",
            " <p>Nullamlacus dui ipsum conseque loborttis non euisque morbi penas dapibulum orna. Urnaultrices quis curabitur phasellentesque congue magnis vestibulum quismodo nulla et feugiat adipiscinia pellentum leo.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </figcaption>\n",
            " </figure>\n",
            " </section>\n",
            " <!-- main content -->\n",
            " <div id=\"homepage\">\n",
            " <!-- services area -->\n",
            " <section id=\"services\" class=\"clear\">\n",
            " <!-- article 1 -->\n",
            " <article class=\"one_third\">\n",
            " <h2>Lorum ipsum dolor</h2>\n",
            " <img src=\"images/demo/80x80.gif\" alt=\"\">\n",
            " <p>Vestibulumaccumsan egestibulum eu justo convallis augue estas aenean elit intesque sed. Facilispede estibulum nulla orna nisl velit elit ac aliquat non tincidunt. Namjusto cras urna urnaretra lor urna neque sed quis orci nulla. Laoremut vitae doloreet condimentumst phasellentes dolor ut a ipsum id consectetus. Inpede cumst vitae ris tellentesque fring intesquet.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </article>\n",
            " <!-- article 2 -->\n",
            " <article class=\"one_third\">\n",
            " <h2>Lorum ipsum dolor</h2>\n",
            " <img src=\"images/demo/80x80.gif\" alt=\"\">\n",
            " <p>Vestibulumaccumsan egestibulum eu justo convallis augue estas aenean elit intesque sed. Facilispede estibulum nulla orna nisl velit elit ac aliquat non tincidunt. Namjusto cras urna urnaretra lor urna neque sed quis orci nulla. Laoremut vitae doloreet condimentumst phasellentes dolor ut a ipsum id consectetus. Inpede cumst vitae ris tellentesque fring intesquet.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </article>\n",
            " <!-- article 3 -->\n",
            " <article class=\"one_third lastbox\">\n",
            " <h2>Lorum ipsum dolor</h2>\n",
            " <img src=\"images/demo/80x80.gif\" alt=\"\">\n",
            " <p>Vestibulumaccumsan egestibulum eu justo convallis augue estas aenean elit intesque sed. Facilispede estibulum nulla orna nisl velit elit ac aliquat non tincidunt. Namjusto cras urna urnaretra lor urna neque sed quis orci nulla. Laoremut vitae doloreet condimentumst phasellentes dolor ut a ipsum id consectetus. Inpede cumst vitae ris tellentesque fring intesquet.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </article>\n",
            " </section>\n",
            " <!-- / services area -->\n",
            " <!-- ########################################################################################## -->\n",
            " <!-- ########################################################################################## -->\n",
            " <!-- ########################################################################################## -->\n",
            " <!-- ########################################################################################## -->\n",
            " <!-- One Quarter -->\n",
            " <section id=\"latest\" class=\"last clear\">\n",
            " <article class=\"one_quarter\">\n",
            " <figure><img src=\"images/demo/215x100.gif\" width=\"215\" height=\"100\" alt=\"\">\n",
            " <figcaption>\n",
            " <h2>Indonectetus facilis</h2>\n",
            " <p>Nullamlacus dui ipsum conseque loborttis non euisque morbi penas dapibulum orna.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " <article class=\"one_quarter\">\n",
            " <figure><img src=\"images/demo/215x100.gif\" width=\"215\" height=\"100\" alt=\"\">\n",
            " <figcaption>\n",
            " <h2>Indonectetus facilis</h2>\n",
            " <p>Nullamlacus dui ipsum conseque loborttis non euisque morbi penas dapibulum orna.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " <article class=\"one_quarter\">\n",
            " <figure><img src=\"images/demo/215x100.gif\" width=\"215\" height=\"100\" alt=\"\">\n",
            " <figcaption>\n",
            " <h2>Indonectetus facilis</h2>\n",
            " <p>Nullamlacus dui ipsum conseque loborttis non euisque morbi penas dapibulum orna.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " <article class=\"one_quarter lastbox\">\n",
            " <figure><img src=\"images/demo/215x100.gif\" width=\"215\" height=\"100\" alt=\"\">\n",
            " <figcaption>\n",
            " <h2>Indonectetus facilis</h2>\n",
            " <p>Nullamlacus dui ipsum conseque loborttis non euisque morbi penas dapibulum orna.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " </section>\n",
            " <!-- / One Quarter -->\n",
            " </div>\n",
            " <!-- / content body -->\n",
            " </div>\n",
            "</div>\n",
            "<!-- Footer -->\n",
            "<div class=\"wrapper row3\">\n",
            " <footer id=\"footer\" class=\"clear\">\n",
            " <p class=\"fl_left\">Copyright &copy; 2012 - All Rights Reserved - <a href=\"#\">Domain Name</a></p>\n",
            " <p class=\"fl_right\">Template by <a href=\"http://www.os-templates.com/\" title=\"Free Website Templates\">OS Templates</a></p>\n",
            " </footer>\n",
            "</div>\n",
            "</body>\n",
            "</html> END"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}